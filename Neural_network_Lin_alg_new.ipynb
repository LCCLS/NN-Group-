{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import statistics\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blur matrix\n",
    "\n",
    "def create_matrix(size):  # first we need a function that creates empty matrices of the size we want (np.empty is not readable)\n",
    "    if int(size) > 0:\n",
    "        s = 1\n",
    "        mat = []\n",
    "        while s <= size:\n",
    "            mat.append([0.0] * size) #the data type of matrix elements is set on creation, so float instead of int\n",
    "            s += 1\n",
    "        mat = np.array(mat)\n",
    "    return mat\n",
    "\n",
    "\n",
    "def create_blur_matrix(size):\n",
    "    blurred_matrix = create_matrix(size)             # create a zeroes matrix of the required size\n",
    "    if size > 1:\n",
    "        for i in range(0, blurred_matrix.shape[1]):  # go through all columns of the matrix\n",
    "            if i == 0:                               # set the edge case for the upper left corner\n",
    "                blurred_matrix[i,i] = 0.8\n",
    "                blurred_matrix[1,i] = 0.2\n",
    "            elif i == (blurred_matrix.shape[1] - 1): # set the edge case for the bottom right corner\n",
    "                blurred_matrix[i, i] = 0.8\n",
    "                blurred_matrix[i-1, i] = 0.2\n",
    "            else:\n",
    "                blurred_matrix[i,i] = 0.6\n",
    "                blurred_matrix[i-1,i] = 0.2\n",
    "                blurred_matrix[i+1,i] = 0.2\n",
    "\n",
    "        return blurred_matrix\n",
    "    \n",
    "\n",
    "    \n",
    "blur_m = create_blur_matrix(25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete first row\n",
    "def first_zeros(vector):\n",
    "    vector[5:] = 0\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift\n",
    "\n",
    "def shift(vector):\n",
    "    changed_copy = np.copy(vector)\n",
    "    vector_copy = np.copy(vector)\n",
    "    changed_copy[-1] = vector_copy[0]\n",
    "    for i in range(len(vector)-1):\n",
    "        changed_copy[i] = vector_copy[i+1]\n",
    "        \n",
    "    return changed_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.693, 0.693, 0.   , 0.693, 0.693, 0.693, 0.693, 0.   , 0.693,\n",
       "       0.693, 0.693, 0.   , 0.693, 0.   , 0.693, 0.693, 0.   , 0.   ,\n",
       "       0.   , 0.693, 0.693, 0.   , 0.   , 0.   , 0.693])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a letter dataset\n",
    "# first letter clean letter\n",
    "# second letter blur matrix\n",
    "# third darken\n",
    "# fourth bold\n",
    "\n",
    "# M\n",
    "M1 = np.array([0.99,0.99,0,0.99,0.99, 0.99,0.99,0,0.99,0.99, 0.99,0,0.99,0,0.99, 0.99,0,0,0,0.99, 0.99,0,0,0,0.99])\n",
    "M2 = np.matmul(blur_m,M1)\n",
    "M3 = M1*0.7\n",
    "M4 = np.array([0.99,0.99,0,0.99,0.99, 0.99,0.99,0,0.99,0.99, 0.99,0.99,0.99,0.99,0.99, 0.99,0.99,0,0.99,0.99, 0.99,0.99,0,0.99,0.99])\n",
    "\n",
    "# O\n",
    "O1 = np.array([0.99,0.99,0.99,0.99,0.99,  0.99,0,0,0,0.99, 0.99,0,0,0,0.99, 0.99,0,0,0,0.99, 0.99,0.99,0.99,0.99,0.99])\n",
    "O2 = np.matmul(blur_m, O1)\n",
    "O3 = O1*0.7\n",
    "O4 = np.array([0.99,0.99,0.99,0.99,0.99, 0.99,0.99,0.99,0.99,0.99, 0.99,0.99,0,0.99,0.99, 0.99,0.99,0.99,0.99,0.99, 0.99,0.99,0.99,0.99,0.99,])\n",
    "\n",
    "\n",
    "#L\n",
    "L1 = np.array([0.99,0,0,0,0,  0.99,0,0,0,0, 0.99,0,0,0,0, 0.99,0,0,0,0, 0.99,0.99,0.99,0.99,0])\n",
    "L2 = np.matmul(blur_m, L1)\n",
    "L3 = L1*0.7\n",
    "L4 = np.array([0.99,0.99,0,0,0,  0.99,0.99,0,0,0, 0.99,0.99,0,0,0, 0.99,0.99,0.99,0.99,0, 0.99,0.99,0.99,0.99,0])\n",
    "\n",
    "\n",
    "#different stuff\n",
    "\n",
    "#E = [0,0.99,0.99,0.99,0,0,0.99,0,0,0,0,0.99,0.99,0.99,0,0,0.99,0,0,0,0,0.99,0.99,0.99,0]\n",
    "#O2 = [0.99,0.99,0.99,0.99,0.99,0.99,0,0,0,0.99,0.99,0,0,0,0.99,0.99,0,0,0,0.99,0.99,0.99,0.99,0.99,0.99]\n",
    "#O_blur = [0.2,0.2,0.2,0.2,0.2,0.4,0.1,0,0.1,0.4,0.4,0.1,0,0.1,0.4,0.4,0.1,0,0.1,0.4,0.2,0.2,0.2,0.2,0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing dataset\n",
    "\n",
    "def preprocessing(list_1):\n",
    "\n",
    "    \"\"\"returns a new list with its characters corrected for noise\n",
    "    \n",
    "    Args:\n",
    "        list_1 (list): a list of integers representing a vector\n",
    "        \n",
    "    Returns: \n",
    "        char_processed (list): a new list corrected for noise\n",
    "        \n",
    "    \"\"\"\n",
    "    char_processed = np.copy(list_1)\n",
    " \n",
    "    for i in range(len(char_processed)):     \n",
    "        char_processed[i] = char_processed[i] - 0.1\n",
    "\n",
    "    return char_processed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# M \n",
    "\n",
    "new_M1 = preprocessing(M1)\n",
    "new_M2 = preprocessing(M2)\n",
    "new_M3 = preprocessing(M3)\n",
    "new_M4 = preprocessing(M4)\n",
    "\n",
    "\n",
    "# O \n",
    "\n",
    "new_O1 = preprocessing(O1)\n",
    "new_O2 = preprocessing(O2)\n",
    "new_O3 = preprocessing(O3)\n",
    "new_O4 = preprocessing(O4)\n",
    "\n",
    "# L\n",
    "\n",
    "new_L1 = preprocessing(L1)\n",
    "new_L2 = preprocessing(L2)\n",
    "new_L3 = preprocessing(L3)\n",
    "new_L4 = preprocessing(L4)\n",
    "\n",
    "\n",
    "\n",
    "#new_M = preprocessing(M)\n",
    "#new_O = preprocessing(O)\n",
    "#new_L = preprocessing(L)\n",
    "#new_E = preprocessing(E)\n",
    "#new_O2 = preprocessing(O2)\n",
    "#new_O_blur = preprocessing(O_blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalise (lst):\n",
    "    normalised = []\n",
    "    i = 0\n",
    "    for i in range(len(lst)):\n",
    "        minimum = min(lst)\n",
    "        maximum = max(lst)\n",
    "        value = (lst[i]-minimum) / (maximum-minimum)\n",
    "        i += 1\n",
    "        normalised.append(value)\n",
    "    return normalised\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# so this function basically just compares the prepocessed letters to the neural network and plots the predictive\n",
    "# percentages. (how sure it is). besides the preprocessing function, and the standardising function, \n",
    "# this is all we need. the rest is just for explaining what actually happens. \n",
    "\n",
    "\n",
    "# decrease bias\n",
    "L_max1 = np.maximum(L1, L2)\n",
    "L_max2 = np.maximum(L3, L4)\n",
    "L_max = np.maximum(L_max1, L_max2)\n",
    "\n",
    "#L_avg = np.array([new_L1, new_L2, new_L3])\n",
    "#L_avg = np.average(L_avg, axis=0)\n",
    "\n",
    "def find_percent(vector):\n",
    "    \n",
    "    \"\"\"returns a list of floats that represents similarity to letters\n",
    "    \n",
    "    Args: \n",
    "        data (list): a list representing weights for each cell in the matrix (vector) letter\n",
    "        \n",
    "    Returns: \n",
    "        percentage (list): a list where each value represents the similarity between data and the NN. \n",
    "    \"\"\"\n",
    "    \n",
    "    NN = [new_M1,new_O1, L_max]\n",
    "    \n",
    "    #NN = [new_M,new_O,new_L,new_E,new_O2,new_O_blur]\n",
    "    percentage = np.matmul(NN,vector)\n",
    "    \n",
    "    return percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.9815   8.9422   5.30244]\n",
      "[9.62926  8.15812  5.028012]\n",
      "[8.01655  5.85934  3.420648]\n",
      "[11.3875  10.3084   7.65468]\n",
      "[ 8.9422  12.7636   8.04672]\n",
      "[ 8.15812 11.58748  7.45866]\n",
      "[5.88904  8.53432  5.341644]\n",
      "[10.1104  11.9716   8.63478]\n",
      "[2.8735 5.7148 6.8706]\n",
      "[2.67748  5.12674  5.459256]\n",
      "[1.64095 3.60016 4.51836]\n",
      "[4.2397  6.1009  7.65468]\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# testing the matrix\n",
    "\n",
    "NN = [new_M1,new_O1, L_max]\n",
    "\n",
    "print(np.matmul(NN, new_M1))\n",
    "print(np.matmul(NN, new_M2))\n",
    "print(np.matmul(NN, new_M3))\n",
    "print(np.matmul(NN, new_M4))\n",
    "\n",
    "\n",
    "print(np.matmul(NN, new_O1))\n",
    "print(np.matmul(NN, new_O2))\n",
    "print(np.matmul(NN, new_O3))\n",
    "print(np.matmul(NN, new_O4))\n",
    "\n",
    "print(np.matmul(NN, new_L1))\n",
    "print(np.matmul(NN, new_L2))\n",
    "print(np.matmul(NN, new_L3))\n",
    "print(np.matmul(NN, new_L4))\n",
    "\n",
    "\n",
    "#print ouput for each picture\n",
    "\n",
    "# M\n",
    "\n",
    "print(np.argmax(find_percent(new_M1)))\n",
    "print(np.argmax(find_percent(new_M2)))\n",
    "print(np.argmax(find_percent(new_M3)))\n",
    "print(np.argmax(find_percent(new_M4)))\n",
    "\n",
    "# O\n",
    "\n",
    "print(np.argmax(find_percent(new_O1)))\n",
    "print(np.argmax(find_percent(new_O2)))\n",
    "print(np.argmax(find_percent(new_O3)))\n",
    "print(np.argmax(find_percent(new_O4)))\n",
    "\n",
    "\n",
    "# L\n",
    "\n",
    "print(np.argmax(find_percent(new_L1)))\n",
    "print(np.argmax(find_percent(new_L2)))\n",
    "print(np.argmax(find_percent(new_L3)))\n",
    "print(np.argmax(find_percent(new_L4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'subplots'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-0840f88717b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Percentage'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_M2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-0840f88717b9>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(data_)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mnums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLetter_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predictive Accuracy of Letter matching'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'subplots'"
     ]
    }
   ],
   "source": [
    "def plot(data_):\n",
    "    data_ = min_max_normalise(data_)\n",
    "    #Letters = ['M', 'O', 'L', 'E(3)', 'O_Scale(4)', 'O_Blur(5)']\n",
    "    Letters = ['M1', 'M2', \"M3\"]\n",
    "    percent = []\n",
    "    precentage = []\n",
    "\n",
    "    matmul_data = np.matmul(NN,data_)\n",
    "    normalized_matmul = (min_max_normalise(matmul_data))\n",
    "        \n",
    "    for i in normalized_matmul:\n",
    "        i = i*100\n",
    "        percent.append(i)\n",
    "    \n",
    "        \n",
    "  \n",
    "    data_ = min_max_normalise(data_)\n",
    "\n",
    "    Letter_dict = {Letters[i]: percent[i] for i in range(len(Letters))}\n",
    "    alpha = list(Letter_dict.keys())\n",
    "    nums = list(Letter_dict.values())\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(alpha, nums)\n",
    "    fig.suptitle('Predictive Accuracy of Letter matching')\n",
    "    ax.set_xlabel('Letters')\n",
    "    ax.set_ylabel('Percentage')\n",
    "    \n",
    "plot(new_M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot2(vector):\n",
    "    \n",
    "    Letters = ['M1', 'M2', \"M3\"]\n",
    "    \n",
    "    ax.set_xlabel('Letters')\n",
    "    ax.set_ylabel('Percentage')\n",
    "    \n",
    "    matplotlib.pyplot.bar(vector, height, width=0.8, bottom=None, *, align='center', data=None, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### all that is following is not necessarilly needed atm and is more for own comprehension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(np.dot(M,M))+'\\t'+str(np.dot(O,M))+'\\t'+str(np.dot(L,M))+'\\t'+str(np.dot(E,M))+'\\t'+str(np.dot(O2,M))+'\\t'+str(np.dot(O_blur,M)))\n",
    "print(str(np.dot(M,O))+'\\t'+str(np.dot(O,O))+'\\t'+str(np.dot(L,O))+'\\t'+str(np.dot(E,O))+'\\t'+str(np.dot(O2,O))+'\\t'+str(np.dot(O_blur,O)))\n",
    "print(str(np.dot(M,L))+'\\t'+str(np.dot(O,L))+'\\t'+str(np.dot(L,L))+'\\t'+str(np.dot(E,L))+'\\t'+str(np.dot(O2,L))+'\\t'+str(np.dot(O_blur,L)))\n",
    "print(str(np.dot(M,E))+'\\t'+str(np.dot(O,E))+'\\t'+str(np.dot(L,E))+'\\t'+str(np.dot(E,E))+'\\t'+str(np.dot(O2,E))+'\\t'+str(np.dot(O_blur,E)))\n",
    "print(str(np.dot(M,O2))+'\\t'+str(np.dot(O,O2))+'\\t'+str(np.dot(L,O2))+'\\t'+str(np.dot(E,O2))+'\\t'+str(np.dot(O2,O2))+'\\t'+str(np.dot(O_blur,O2)))\n",
    "print(str(np.dot(M,O_blur))+'\\t'+str(np.dot(O,O_blur))+'\\t'+str(np.dot(L,O_blur))+'\\t'+str(np.dot(E,O_blur))+'\\t'+str(np.dot(O2,O_blur))+'\\t'+str(np.dot(O_blur,O_blur)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(np.dot(new_M,new_M))+'\\t'+str(np.dot(new_O,new_M))+'\\t'+str(np.dot(new_L,new_M))+'\\t'+str(np.dot(new_E,new_M))+'\\t'+str(np.dot(new_O2,new_M))+'\\t'+str(np.dot(new_O_blur,new_M)))\n",
    "print(str(np.dot(new_M,new_O))+'\\t'+str(np.dot(new_O,new_O))+'\\t'+str(np.dot(new_L,new_O))+'\\t'+str(np.dot(new_E,new_M))+'\\t'+str(np.dot(new_O2,new_M))+'\\t'+str(np.dot(new_O_blur,new_M)))\n",
    "print(str(np.dot(new_M,new_L))+'\\t'+str(np.dot(new_O,new_L))+'\\t'+str(np.dot(new_L,new_L))+'\\t'+str(np.dot(new_E,new_M))+'\\t'+str(np.dot(new_O2,new_M))+'\\t'+str(np.dot(new_O_blur,new_M)))\n",
    "print(str(np.dot(new_M,new_E))+'\\t'+str(np.dot(new_O,new_E))+'\\t'+str(np.dot(new_L,new_E))+'\\t'+str(np.dot(new_E,new_E))+'\\t'+str(np.dot(new_O2,new_M))+'\\t'+str(np.dot(new_O_blur,new_M)))\n",
    "print(str(np.dot(new_M,new_O2))+'\\t'+str(np.dot(new_O,new_O2))+'\\t'+str(np.dot(new_L,new_O2))+'\\t'+str(np.dot(new_E,new_O2))+'\\t'+str(np.dot(new_O2,new_O2))+'\\t'+str(np.dot(new_O_blur,new_M)))\n",
    "print(str(np.dot(new_M,new_O_blur))+'\\t'+str(np.dot(new_O,new_O_blur))+'\\t'+str(np.dot(new_L,new_O_blur))+'\\t'+str(np.dot(new_E,new_O_blur))+'\\t'+str(np.dot(new_O2,new_O_blur))+'\\t'+str(np.dot(new_O_blur,new_O_blur)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_percent(data):\n",
    "    \n",
    "    \"\"\"returns a list of floats that represents similarity to letters\n",
    "    \n",
    "    Args: \n",
    "        data (list): a list representing weights for each cell in the matrix (vector) letter\n",
    "        \n",
    "    Returns: \n",
    "        percentage (list): a list where each value represents the similarity between data and the NN. \n",
    "    \"\"\"\n",
    "    \n",
    "    NN = [new_M,new_O,new_L,new_E,new_O2,new_O_blur]\n",
    "    percentage = np.matmul(NN,data)\n",
    "    \n",
    "    return percentage\n",
    "    \n",
    "\n",
    "    \n",
    "print(matmul(new_M))\n",
    "print(matmul(new_O))\n",
    "print(matmul(new_L))\n",
    "print(matmul(new_E))\n",
    "print(matmul(new_O2))\n",
    "print(matmul(new_O_blur))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmax(np.matmul(NN,new_O)))\n",
    "print(np.argmax(np.matmul(NN,new_M)))\n",
    "print(np.argmax(np.matmul(NN,new_L)))\n",
    "print(np.argmax(np.matmul(NN,new_E)))\n",
    "print(np.argmax(np.matmul(NN,new_E)))\n",
    "print(np.argmax(np.matmul(NN,new_O2)))\n",
    "print(np.argmax(np.matmul(NN,new_O_blur)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
